import os

localrules: 
    ReadCounts, SplitFasta, MergeSam, UpdateNCBI, TaxonomyFiltered, TaxonomyUnfiltered

configfile: "config.yaml"

SAMPLES = config['samplenames']
CHUNKS = [str(i) for i in list(range(0,config['minimap']['chunks']))]
CWD = os.getcwd()

rule all:
    input:                
        expand(os.path.join(CWD, "7-r2c", "{sample}.{type}.reads.{filt}.txt"), sample = SAMPLES, 
                type = ["NCBI", "GTDB"], filt = ["unfiltered", "filtered"]),
                
        expand(os.path.join(CWD, "8-c2c", "{sample}.{type}.counts.{filt}.txt"), sample = SAMPLES, 
                type = ["NCBI", "GTDB"], filt = ["unfiltered", "filtered"]),

        expand(os.path.join(CWD, "9-kraken-mpa-reports", "{sample}.diamond_megan.kreport.filtered.txt"), sample = SAMPLES),
        expand(os.path.join(CWD, "9-kraken-mpa-reports", "{sample}.diamond_megan.mpa.filtered.txt"), sample = SAMPLES),
        expand(os.path.join(CWD, "9-kraken-mpa-reports", "{sample}.diamond_megan.kreport.unfiltered.txt"), sample = SAMPLES),
        expand(os.path.join(CWD, "9-kraken-mpa-reports", "{sample}.diamond_megan.mpa.unfiltered.txt"), sample = SAMPLES)


rule ReadCounts:
    input: 
        os.path.join(CWD, "inputs", "{sample}.fasta")
    output: 
        os.path.join(CWD, "6-rma", "{sample}.readcounts.txt")
    conda:
        "envs/general.yml"
    threads: 2
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.ReadCounts.tsv")
    shell:
        "grep -c '>' {input} > {output}"


##################################################
# Minimap prep and run

rule SplitFasta:
    input: 
        os.path.join(CWD, "inputs", "{sample}.fasta")
    output: 
        temp(expand(os.path.join(CWD, "1-chunks", "{{sample}}.fasta_chunk_000000{piece}"), piece = CHUNKS))
    conda:
        "envs/general.yml"
    threads: 1
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.SplitFasta.tsv")
    params:
        chunks = config['minimap']['chunks']
    shell:
        "fastasplit -c {params.chunks} -f {input} -o 1-chunks/"

rule RunMinimap:
    input:
        os.path.join(CWD, "1-chunks", "{sample}.fasta_chunk_000000{piece}")
    output:
        temp(os.path.join(CWD, "2-minimap", "{sample}.{piece}.sam"))
    conda:
        "envs/general.yml"
    threads: config['minimap']['threads']
    params:
        db = config['minimap']['db'],
        secondary = config['minimap']['secondary']
    log: 
        os.path.join(CWD, "logs", "{sample}.{piece}.RunMinimap.log")
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.{piece}.RunMinimap.tsv")
    shell:
        "minimap2 -ax map-ont -k 15 -w 10 -I 10G -g 5000 -r 2000 -N {params.secondary} "
        "--lj-min-ratio 0.5 -A 2 -B 5 -O 5,56 -E 4,1 -z 400,50 --sam-hit-only "
        "-t {threads} {params.db} {input} 1> {output} 2> {log}"

##################################################
# MEGAN RMA prep and run
        
rule SortSam:
    input:
        os.path.join(CWD, "2-minimap", "{sample}.{piece}.sam")
    output:
        temp(os.path.join(CWD, "3-sorted", "{sample}.{piece}.sorted.sam"))
    conda:
        "envs/general.yml"
    threads: 8
    params:
        temp = config['minimap']['tempdir']
    log:
        os.path.join(CWD, "logs", "{sample}.{piece}.SortSam.log")
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.{piece}.SortSam.tsv")
    shell:
        "sort -T {params.temp} --parallel=8 -V -k1,1 {input} 1> {output} 2> {log}"

rule MergeSam:
    input:
        expand(os.path.join(CWD, "3-sorted", "{{sample}}.{piece}.sorted.sam"), piece = CHUNKS)
    output:
        os.path.join(CWD, "4-merged", "{sample}.merged.sam")
    conda:
        "envs/general.yml"
    threads: 1
    log: 
        os.path.join(CWD, "logs", "{sample}.MergeSam.log")
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.MergeSam.tsv")
    shell:
        "python scripts/sam-merger-minimap.py -i {input} -o {output} -l {log}"

rule ParseSam:
    input:
        os.path.join(CWD, "4-merged", "{sample}.merged.sam")
    output:
        os.path.join(CWD, "4-merged", "{sample}.reads.txt")
    conda:
        "envs/general.yml"
    threads: 8
    log: 
        os.path.join(CWD, "logs", "{sample}.ParseSam.log")
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.ParseSam.tsv")
    shell:
        "python scripts/Parse-SAM.py -s {input} -o {output} -l {log}"
        
rule SortFasta:
    input:
        fasta = os.path.join(CWD, "inputs", "{sample}.fasta"),
        reads = os.path.join(CWD, "4-merged", "{sample}.reads.txt")
    output:
        os.path.join(CWD, "5-fasta-sort", "{sample}.sorted.fasta")
    conda:
        "envs/general.yml"
    threads: 8
    log: 
        os.path.join(CWD, "logs", "{sample}.SortFasta.log")
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.SortFasta.tsv")
    shell:
        "python scripts/Sort-Fasta-Records-by-SAM-BioPython.py -f {input.fasta} "
        "-r {input.reads} -o {output} -l {log}"

rule MakeRMAfiltered:
    input:
        sam = os.path.join(CWD, "4-merged", "{sample}.merged.sam"),
        reads = os.path.join(CWD, "5-fasta-sort", "{sample}.sorted.fasta")
    output:
        expand(os.path.join(CWD, "6-rma", "{{sample}}_filtered.nucleotide.{mode}.rma"), mode = config['sam2rma']['readassignmentmode'])
    conda:
        "envs/general.yml"
    threads: config['sam2rma']['threads']
    params:
        sam2rma = config['sam2rma']['path'],
        db = config['sam2rma']['db'],
        ram = config['sam2rma']['readassignmentmode'],
        ms = config['sam2rma']['minSupportPercent'],
        mrc = config['sam2rma']['minPercentReadCover']
    log: 
        os.path.join(CWD, "logs", f"{{sample}}.MakeRMA.filtered.{config['sam2rma']['readassignmentmode']}.log")
    benchmark: 
        os.path.join(CWD, "benchmarks", f"{{sample}}.MakeRMA.filtered.{config['sam2rma']['readassignmentmode']}.tsv")
    shell:
        "{params.sam2rma} -i {input.sam} -r {input.reads} -o {output} -lg -alg longReads "
        "-t {threads} -mdb {params.db} -ram {params.ram} --minSupportPercent {params.ms} "
        "-mrc {params.mrc} -v 2> {log}"

rule MakeRMAunfiltered:
    input:
        sam = os.path.join(CWD, "4-merged", "{sample}.merged.sam"),
        reads = os.path.join(CWD, "5-fasta-sort", "{sample}.sorted.fasta")
    output:
        expand(os.path.join(CWD, "6-rma", "{{sample}}_unfiltered.nucleotide.{mode}.rma"), mode = config['sam2rma']['readassignmentmode'])
    conda:
        "envs/general.yml"
    threads: config['sam2rma']['threads']
    params:
        sam2rma = config['sam2rma']['path'],
        db = config['sam2rma']['db'],
        ram = config['sam2rma']['readassignmentmode'],
        ms = config['sam2rma']['minSupportPercent'],
        mrc = config['sam2rma']['minPercentReadCover']
    log: 
        os.path.join(CWD, "logs", f"{{sample}}.MakeRMA.unfiltered.{config['sam2rma']['readassignmentmode']}.log")
    benchmark: 
        os.path.join(CWD, "benchmarks", f"{{sample}}.MakeRMA.unfiltered.{config['sam2rma']['readassignmentmode']}.tsv")
    shell:
        "{params.sam2rma} -i {input.sam} -r {input.reads} -o {output} -lg -alg longReads "
        "-t {threads} -mdb {params.db} -ram {params.ram} --minSupportPercent 0 "
        "-mrc {params.mrc} -v 2> {log}"


##################################################
# MEGAN RMA summaries - Read classification


rule RunR2CforNCBIfiltered:
    input:
        expand(os.path.join(CWD, "6-rma", "{{sample}}_filtered.nucleotide.{mode}.rma"), mode = config['sam2rma']['readassignmentmode'])
    output:
        os.path.join(CWD, "7-r2c", "{sample}.NCBI.reads.filtered.txt")
    conda:
        "envs/general.yml"
    threads: 
        config['rma2info']['threads']
    params:
        rma2info = config['rma2info']['path']
    log: 
        os.path.join(CWD, "logs", "{sample}.RunR2CforNCBIfiltered.log")
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.RunR2CforNCBIfiltered.tsv")
    shell:
        "{params.rma2info} -i {input} -o {output} -r2c Taxonomy -n &> {log}"

rule RunR2CforNCBIunfiltered:
    input:
        expand(os.path.join(CWD, "6-rma", "{{sample}}_unfiltered.nucleotide.{mode}.rma"), mode = config['sam2rma']['readassignmentmode'])
    output:
        os.path.join(CWD, "7-r2c", "{sample}.NCBI.reads.unfiltered.txt")
    conda:
        "envs/general.yml"
    threads: 
        config['rma2info']['threads']
    params:
        rma2info = config['rma2info']['path']
    log: 
        os.path.join(CWD, "logs", "{sample}.RunR2CforNCBIunfiltered.log")
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.RunR2CforNCBIunfiltered.tsv")
    shell:
        "{params.rma2info} -i {input} -o {output} -r2c Taxonomy -n &> {log}"

rule RunR2CforGTDBfiltered:
    input:
        expand(os.path.join(CWD, "6-rma", "{{sample}}_filtered.nucleotide.{mode}.rma"), mode = config['sam2rma']['readassignmentmode'])
    output:
        os.path.join(CWD, "7-r2c", "{sample}.GTDB.reads.filtered.txt")
    conda:
        "envs/general.yml"
    threads: 
        config['rma2info']['threads']
    params:
        rma2info = config['rma2info']['path']
    log: 
        os.path.join(CWD, "logs", "{sample}.RunR2CforGTDBfiltered.log")
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.RunR2CforGTDBfiltered.tsv")
    shell:
        "{params.rma2info} -i {input} -o {output} -r2c GTDB -n &> {log}"

rule RunR2CforGTDBunfiltered:
    input:
        expand(os.path.join(CWD, "6-rma", "{{sample}}_unfiltered.nucleotide.{mode}.rma"), mode = config['sam2rma']['readassignmentmode'])
    output:
        os.path.join(CWD, "7-r2c", "{sample}.GTDB.reads.unfiltered.txt")
    conda:
        "envs/general.yml"
    threads: 
        config['rma2info']['threads']
    params:
        rma2info = config['rma2info']['path']
    log: 
        os.path.join(CWD, "logs", "{sample}.RunR2CforGTDBunfiltered.log")
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.RunR2CforGTDBunfiltered.tsv")
    shell:
        "{params.rma2info} -i {input} -o {output} -r2c GTDB -n &> {log}"



##################################################
# MEGAN RMA summaries - Class counts


rule RunC2CforGTDBfiltered:
    input:
        expand(os.path.join(CWD, "6-rma", "{{sample}}_filtered.nucleotide.{mode}.rma"), mode = config['sam2rma']['readassignmentmode'])
    output:
        os.path.join(CWD, "8-c2c", "{sample}.GTDB.counts.filtered.txt")
    conda:
        "envs/general.yml"
    threads: 
        config['rma2info']['threads']
    params:
        rma2info = config['rma2info']['path']
    log: 
        os.path.join(CWD, "logs", "{sample}.RunC2CforGTDBfiltered.log")
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.RunC2CforGTDBfiltered.tsv")
    shell:
        "{params.rma2info} -i {input} -o {output} -c2c GTDB -n &> {log}"

rule RunC2CforGTDBunfiltered:
    input:
        expand(os.path.join(CWD, "6-rma", "{{sample}}_unfiltered.nucleotide.{mode}.rma"), mode = config['sam2rma']['readassignmentmode'])
    output:
        os.path.join(CWD, "8-c2c", "{sample}.GTDB.counts.unfiltered.txt")
    conda:
        "envs/general.yml"
    threads: 
        config['rma2info']['threads']
    params:
        rma2info = config['rma2info']['path']
    log: 
        os.path.join(CWD, "logs", "{sample}.RunC2CforGTDBunfiltered.log")
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.RunC2CforGTDBunfiltered.tsv")
    shell:
        "{params.rma2info} -i {input} -o {output} -c2c GTDB -n &> {log}"

rule RunC2CforNCBIfiltered:
    input:
        expand(os.path.join(CWD, "6-rma", "{{sample}}_filtered.nucleotide.{mode}.rma"), mode = config['sam2rma']['readassignmentmode'])
    output:
        os.path.join(CWD, "8-c2c", "{sample}.NCBI.counts.filtered.txt")
    conda:
        "envs/general.yml"
    threads: 
        config['rma2info']['threads']
    params:
        rma2info = config['rma2info']['path']
    log: 
        os.path.join(CWD, "logs", "{sample}.RunC2CforNCBIfiltered.log")
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.RunC2CforNCBIfiltered.tsv")
    shell:
        "{params.rma2info} -i {input} -o {output} -c2c Taxonomy -n -r &> {log}"
        
rule RunC2CforNCBIunfiltered:
    input:
        expand(os.path.join(CWD, "6-rma", "{{sample}}_unfiltered.nucleotide.{mode}.rma"), mode = config['sam2rma']['readassignmentmode'])
    output:
        os.path.join(CWD, "8-c2c", "{sample}.NCBI.counts.unfiltered.txt")
    conda:
        "envs/general.yml"
    threads: 
        config['rma2info']['threads']
    params:
        rma2info = config['rma2info']['path']
    log: 
        os.path.join(CWD, "logs", "{sample}.RunC2CforNCBIunfiltered.log")
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.RunC2CforNCBIunfiltered.tsv")
    shell:
        "{params.rma2info} -i {input} -o {output} -c2c Taxonomy -n -r &> {log}"

##################################################
# Make taxonomic reports

rule UpdateNCBI:
    input:
        expand(os.path.join(CWD, "8-c2c", "{sample}.NCBI.counts.unfiltered.txt"), sample = SAMPLES)
    output:
        dummy = os.path.join(CWD, "9-kraken-mpa-reports", "NCBI-updated.txt"),
        taxdump = temp(os.path.join(CWD, "taxdump.tar.gz"))
    conda:
        "envs/general.yml"
    threads: 
        1
    log: 
        os.path.join(CWD, "logs", "UpdateNCBI.prot.log")
    benchmark: 
        os.path.join(CWD, "benchmarks", "UpdateNCBI.prot.tsv")
    shell:
        "python scripts/Run_ete3_NCBI_update.py -i {input} -o {output.dummy} &> {log}"

rule TaxonomyUnfiltered:
    input:
        c2c = os.path.join(CWD, "8-c2c", "{sample}.NCBI.counts.unfiltered.txt"),
        ncbiready = os.path.join(CWD, "9-kraken-mpa-reports", "NCBI-updated.txt"),
        taxdump = os.path.join(CWD, "taxdump.tar.gz"),
        readcount = os.path.join(CWD, "6-rma", "{sample}.readcounts.txt")
    output:
        inter1 = temp(os.path.join(CWD, "9-kraken-mpa-reports", "{sample}.diamond_megan.unfiltered.taxnames.txt")),
        inter2 = temp(os.path.join(CWD, "9-kraken-mpa-reports", "{sample}.diamond_megan.unfiltered.taxids.txt")),
        kreport = os.path.join(CWD, "9-kraken-mpa-reports", "{sample}.diamond_megan.kreport.unfiltered.txt"),
        mpa = os.path.join(CWD, "9-kraken-mpa-reports", "{sample}.diamond_megan.mpa.unfiltered.txt")
    conda:
        "envs/general.yml"
    threads: 
        1
    log: 
        os.path.join(CWD, "logs", "{sample}.TaxonomyUnfilteredlog")
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.TaxonomyUnfiltered.tsv")
    shell:
        "python scripts/Convert_MEGAN_RMA_NCBI_c2c-snake.py -i {input.c2c} -o1 {output.inter1} "
        "-o2 {output.inter2} -m {output.mpa} -k {output.kreport} -r {input.readcount} &> {log}"

rule TaxonomyFiltered:
    input:
        c2c = os.path.join(CWD, "8-c2c", "{sample}.NCBI.counts.filtered.txt"),
        ncbiready = os.path.join(CWD, "9-kraken-mpa-reports", "NCBI-updated.txt"),
        taxdump = os.path.join(CWD, "taxdump.tar.gz"),
        readcount = os.path.join(CWD, "6-rma", "{sample}.readcounts.txt")
    output:
        inter1 = temp(os.path.join(CWD, "9-kraken-mpa-reports", "{sample}.diamond_megan.filtered.taxnames.txt")),
        inter2 = temp(os.path.join(CWD, "9-kraken-mpa-reports", "{sample}.diamond_megan.filtered.taxids.txt")),
        kreport = os.path.join(CWD, "9-kraken-mpa-reports", "{sample}.diamond_megan.kreport.filtered.txt"),
        mpa = os.path.join(CWD, "9-kraken-mpa-reports", "{sample}.diamond_megan.mpa.filtered.txt")
    conda:
        "envs/general.yml"
    threads: 
        1
    log: 
        os.path.join(CWD, "logs", "{sample}.TaxonomyFilteredlog")
    benchmark: 
        os.path.join(CWD, "benchmarks", "{sample}.TaxonomyFiltered.tsv")
    shell:
        "python scripts/Convert_MEGAN_RMA_NCBI_c2c-snake.py -i {input.c2c} -o1 {output.inter1} "
        "-o2 {output.inter2} -m {output.mpa} -k {output.kreport} -r {input.readcount} &> {log}"
